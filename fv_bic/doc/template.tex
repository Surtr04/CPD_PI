\documentclass[twocolumn,10pt]{scrartcl}
\usepackage{fullpage}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{ucs}
\usepackage[T1]{fontenc}
\usepackage[utf8x]{inputenc}
\usepackage[english]{babel}
\usepackage{indentfirst}
\usepackage[small]{caption}

\usepackage[paper=a4paper,top=2cm,left=1.5cm,right=1.5cm,bottom=2cm,foot=1cm]{geometry}

\usepackage{amsmath}
\usepackage[retainorgcmds]{IEEEtrantools}%	IEEEeqnarray

\usepackage{multi row}%	row span in tables

\usepackage{varioref}%	context sensitive references (prints page when far away)
\usepackage{hyperref}%	hyperlinks, references with automatic descriptions
\usepackage{hypcap}
\usepackage{titlesec}

\usepackage{listings}
\lstset{
	language=c,
	basicstyle=\footnotesize,
	showtabs=true,
	tabsize=3,
	showtabs=false,
}

\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}

\renewcommand*\thesection{\arabic{section}}

%	title page
\titlehead{Universidade do Minho \hfill Parallel and Distributed Computing	\\
		Master's Degree in Informatics Engineering}
\title{Profiling}
\subtitle{N-Body}
\author{Miguel Palhas\\pg19808@alunos.uminho.pt}
\date{Braga, January 2012}
\subject{Computing Systems and Performance}

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SECTION 1: INTRODUCTION
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

This paper is meant to show the result of the work on the proposed assignment. It consists on a full laptop characterization shown in \autoref{ref:2.1.3} along with it's roofline model in \autoref{ref:2.2}. In \autoref{ref:3} a description of the proposed algorithm, N-Body, is done, followed by the work done using the PAPI library to analyze it. The most relevant results and conclusions are shown in \autoref{ref:4}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SECTION 2: ROOFLINE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Roofline}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSECTION 2.1: Profiling
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Profiling}
The computer characterized here is the HP dv5-1170ep, released in 2008.

Most of the hardware was obtained from the Intel ARK Website \cite{ark} and from standard Linux tools:
\begin{description}
\item[dmidecode] Tool for hardware dump from BIOS information;
\item[lscpu] Lists CPU information;
\item[lshw] Lists hardware information
\item[getconf] Lists various configuration variables (e.g. cache organization values)
\end{description}

AIDA64 Extreme Edition for Windows 7 was used to measure memory latencies. It's results were then compared against the previously obtained data to ensure it's accuracy.
Some of the data is theoretically calculated based on the given hardware characteristics. This, of course, represents only a theoretical limit for the hardware, and not actually measured data.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSUBSECTION 2.1.1: Peak FP Performance
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Peak Floating-Point Performance}
In order to keep coherency with the Roofline paper\cite{roofline}, Peak FP Performance was measured using double-precision floating point numbers. The formula to calculate the maximum double precision floating point throughput is:

$$\mathrm{Flop/s_{max}} = T_{\mathrm{FP}} \times f_{\mathrm{clock}} \times \#_{\mathrm{cores}}$$

Where $T_{\mathrm{FP}}$ is the double precision floating point throughput of each core.

The CPU in question, Core 2 Duo P8600, has two cores working with a clock rate of 2.4 GHz. Being based on the Core micro architecture, each core has one execution unit for 128-bit floating point addition, and one for multiplication. When considering SIMD operations, with the SSE and MMX extensions, then each 128-bit register can carry two double precision floating point values, thus effectively doubling the throughput. With an ideal multiply/add balance, four floating point operations can run in parallel.

\begin{IEEEeqnarray}{CrClC}
\Rightarrow		& \mathrm{Flop/s_{max}} & = & 4 \times \left (2.4 \times 10^9 \right ) \times 2 & \Leftrightarrow	\nonumber \\
\Leftrightarrow	& \mathrm{Flop/s_{max}} & = & 19.2\;\mathrm{GFlop/s} & \nonumber
\end{IEEEeqnarray}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSUBSECTION 2.1.2: Peak Mem BW
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Peak Memory Bandwidth}
This value can be calculated based on the memory clock rate and the memory bus. Multiple channels should also be taken into account.
The memory is a SDRAM DDR2 operating at a clock rate of 800MHz, and using two modules, taking advantage of the dual-channel. The bus width is 64 bits (or 8 Bytes)

\begin{IEEEeqnarray}{CrClC}
\Rightarrow		& \mathrm{BW_{max}} & = & MEM_{\mathrm{clock}} \times bus_{\mathrm{width}} \times \#\mathrm{channels} & \Leftrightarrow \\
\Leftrightarrow	& \mathrm{BW_{max}} & = & (800 \times 10^9) \times 64 \times 2 & \Leftrightarrow \nonumber \\
\Leftrightarrow & \mathrm{BW_{max}} & = & 12.8\;\mathrm{GB/s} & \nonumber
\end{IEEEeqnarray}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSUBSECTION 2.1.3: Summary
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Summary}
\label{ref:2.1.3}
The full characterization of the laptop is summarized in \autoref{tab:profile}

\begin{table}[!htp]
	\begin{center}
		\begin{tabular}{|rl|}
			\multicolumn{2}{c}{\textbf{Laptop}}				\\
			\hline
				Manufacturer		&	HP					\\
				Model				&	Pavilion dv5 1170ep	\\
			\hline
			\multicolumn{2}{c}{} 							\\
			\multicolumn{2}{c}{\textbf{Processor}} 			\\
			\hline
				Manufacturer:		&	Intel				\\
				Model:				&	P8600				\\
				$\mu$-arch			&	Core				\\
				Codename			&	Penryn-3M			\\
				Clock frequency		&	2.4 GHz				\\
				Cores				&	2					\\
				Threads:			&	2					\\
				Peak Flop/s			&	19.2 GFlop/s		\\
			\hline
		\end{tabular}
	\end{center}

	\begin{center}
		\begin{tabular}{|c|rl|}
			\multicolumn{3}{c}{\textbf{Memory}}		\\
			\hline
			\multicolumn{1}{|c|}{\multirow{5}{*}{L1}}
				&	Scope			&	Core		\\
				&	Size			&	32KB + 32KB	\\
				&	Associativity	&	8-way		\\
				&	Line Size		&	64 B		\\
				&	Write Policy	&	Write-back	\\
			\hline
			\multicolumn{1}{|c|}{\multirow{5}{*}{L2}}
				&	Scope			&	shared		\\
				&	Size			&	3MB			\\
				&	Associativity	&	12-way		\\
				&	Line Size		&	64 B		\\
				&	Write Policy	&	Write-back	\\
			\hline
			\multicolumn{1}{|c|}{\multirow{6}{*}{RAM}}
				&	Type			&	SDRAM DDR2 PC6400	\\
				&	Frequency		&	800 MHz				\\
				&	Num. Channels	&	2					\\
				&	Size			&	4 GB				\\
				&	Latency			&	81.1 ns				\\
				&	Peak Bandwidth	&	12.8 GB/s			\\
			\hline			
		\end{tabular}
	\end{center}
	\caption{Laptop characterization \label{tab:profile}}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SUBSECTION 2.2. ROOFLINE MODEL
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Roofline}
\label{ref:2.2}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUSUBSBECTION 2.2.1. ROOFS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Roofs}

Based on the data gathered from the laptop characterization, and the information from the Roofline paper \cite{roofline}, both roofs for the model can be easily calculated by the formula:

$$ Flops/sec = min(Peak Flops/sec, MemBW \times Op. Intensity ) $$

The first part of the $\mathrm{min}$ function gives the CPU roof, which is equal to the CPU's peak Flop performance. The memory roof increases linearly with the Operational Intensity (as the operational intensity increases, problems become more CPU-bound and less memory-bound)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSUBSECTION 2.2.2. CEILINGS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Ceilings}

Ceilings were added to the model by gradually recalculating the roofs without a certain architecture characteristic. Each ceiling is given by the value of the previous ceiling (with the roof being the base value), divided by a factor which represents the weight that the removed characteristic had in the performance. The ceilings estimated were:
\begin{description}
	\item[All cores used]This corresponds to the roof, where all the resources are considered.
	\item[Mul/Add balance, No TLP (only one core)]This ceiling considers only the usage of a single core, against two cores in the previous. This represents a reduction in peak performance by a factor of 2, so the ceiling has half the value of the previous one.
	\item[With SIMD (no Mul/Add balance)]Here, it was considered that multiplication and addition instructions were not balanced. Without this balance, the hardware won't be used to it's full potential. Each core has two SSE units, one unit to process multiplications and another for additions. It also has two normal units, but they can't be used at the same time. So if only one of those is busy at each instant, the performance is again halved.
	\item[ILP Only (no SIMD)]Finally SIMD were removed. Since everything was measured using double-precision floating point numbers, SIMD would allow two FP operations to be processed each clock cycle. Without SIMD, only one will be processed, which is half of the original performance
\end{description}

For the memory, only one ceiling was estimated. This ceiling occurs when dual channel is removed, which theoretically drops memory bandwidth to half its value.

\autoref{tab:ceilings} shows a summary of all the ceilings calculated, and it's value.

\begin{table}[!htp]
	\begin{center}
		\begin{tabular}{|c|c|c|}
				\hline
				&	\textbf{Ceiling}	&	\textbf{Value (GFlops)}	\\
				\hline
				\hline
			\multicolumn{1}{|c|}{\multirow{4}{*}{CPU}}
				&	All cores used		&	19.2					\\
				&	Mul/Add balance		&	9.6						\\
				&	With SIMD			&	4.8						\\
				&	ILP Only			&	2.4						\\
			\hline
			\hline
			\multicolumn{1}{|c|}{\multirow{2}{*}{Memory}}
				&	All channels used	&	12.8\footnotemark		\\
				&	No dual channel		&	6.4						\\
				\hline
		\end{tabular}
	\end{center}
	\caption{Ceiling values for Roofline Mode \label{tab:ceilings}}
\end{table}
\footnotetext{This value corresponds to an operational intensity of 1}

\autoref{fig:roofline} shows the graph for the Roofline model. \autoref{fig:roofline4} shows the same Roofline model overlapped with the Roofline for the Opteron X4, for comparison.

\newpage

\begin{figure}[!htp]
	\includegraphics[width=\columnwidth]{images/joined.eps}
	\caption[Roofline Model with Opteron X4]{Roofline Model overlapped with Opteron X4 \label{fig:rooflinex4}}
\end{figure}

The main difference between the P8600 that was used and the Opteron X4 is in the number of cores. Both processors have two SSE units, and two regular units (sharing the issue port with the SSE units) per core, with each SSE instructions using 128 bit registers in both processors. So each one can process 2 double precision floating points per cycle(assuming a fully pipelined architecture with a latency of one cycle per instruction). The clock frequency is roughly the same (2.4 GHz in the P8600, 2.3 GHz in the Opteron X4). The Opteron system showed here uses a dual-socket architecture, with two Opteron X4, for a total of 8 cores, four times more than the laptop architecture. This matches the expected values for the roofline model, which shows that the peak performance for the dual Opteron X4 system is around 4 times higher than the laptop.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SECTION 3. ALGORITHM ANALYSIS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algorithm Analysis}
\label{ref:3}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSECTION 3.1. ALGORITHM
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The N-Body Algorithm}

In this report, it was required to analyze the performance of the \emph{N-Body} algorithm, which is used to simulate the interaction between a set of objects, and the interactions between them. One example application of this algorithm is simulating the influence that the planet's gravitational force on the other planets in the set, and estimate it's position in the future.

The formula implemented for this analysis is the following:

\begin{IEEEeqnarray}{C}
	\begin{cases}
	{\forall}_{x \in N} \; p_{x}(t + {\Delta}t) = p_{x}(t) + v_{x}(t) + \frac{1}{2}{\Delta}t^{2}a_{x}(t) \nonumber \\
	\\
	\; a_{x}(t) = G \sum_{i=1}^{N} \frac{m_{i} | p_{x} - p{i} |}{| p_{x} - p_{i} |} \nonumber \\
	\end{cases}
\end{IEEEeqnarray}

The formula states that the position of an object $x$ after ${\Delta}t$ units of time, is given by the sum between its previous position, velocity and acceleration. The acceleration is computed iteratively, based on the mass and position of all the other objects in the set. In general, the naive version of this algorithm (the one tested here) runs on $\Theta(N^{2})$. There are much better implementations of this algorithm, down to a complexity of $O(N log(N))$, however they were not the object of study here.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSECTION 3.2. PARTICULAR PROBLEM: SQUARE ROOT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Particular Problem: Square root}

The algorithm requires  calculation of a square root for every interaction, for a total of $N^{2}$ square root calculations for the whole algorithm. This C standard implementation uses Newton's iterative method, which has an execution time that cannot be estimated easily. Since the focus here is on performance analysis rather that accurate results, it was decided that a different square root implementation should be used.

The selected implementation was taken from a small comparison of square root implementations (see \cite{sqrt}), and it was the one on the article that provided the nearest speed and accuracy compared to the standard implementation, and also had support for double precision floats (some of the implementations didn't because they assumed a 32-bit number and relied on bit shift operations).


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSECTION 3.3. TEST CASES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Test Cases}

Six test cases were chosen, so that two cases could fit on each memory level. \autoref{tab:testcases} specifies their names and details. For a simulation with the algorithm, each object requires a total of 10 double precision floats: 3 for position vector, 3 for velocity, 1 for mass, and 3 for a temporary vector to hold the next position, which was required to keep the newly calculated position of the object, since the original position vector could only be updated after the entire iteration was over.

\begin{table}[!htp]
	\begin{center}
		\begin{tabular}{|l|l|l|}
			\hline
			\textbf{Test Name}	&	\textbf{Size (N)}	&	\textbf{Size}	\\
			\hline
			L1\_1				&	64					&	5 KB			\\
			L1\_2				&	128					&	10 KB			\\
			L2\_1				&	8192				&	0.625 MB		\\
			L2\_2				&	16384				&	1.25 MB			\\
			RAM\_1				&	65536				&	5 MB			\\
			RAM\_2				&	131072				&	10 MB			\\
			\hline
		\end{tabular}
	\end{center}
	\caption{Test cases used in the analysis \label{tab:testcases}}
\end{table}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSECTION 3.4. TEST METHODOLOGY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Test Methodology}

To measure the implementation's performance, Performance API (PAPI) was used. This tool provides a set of counters, directly supported by the processor hardware, to enable low-level event measures. In general, the counters used allowed to count:
\begin{itemize}
	\item total number of cycles and instructions
	\item number of mul/add/div/load/store operations
	\item accesses and misses of both cache levels
\end{itemize}

Most of the counters are native to the architecture. Of all the selected, only the ones dealing with L2 cache are derived, and may not be as reliable. So in total, each object uses $10 \times 64 / 8 = 80$ Bytes.

The algorithm was implemented in C, along with function calls to PAPI to manage hardware counters. The code was compiled with the level 3 optimization flag.

All counters were ran on a dedicated process, to avoid conflicts. To avoid possible problems with core affinity and thread scheduling, only one core was enabled on the laptop, and all major processes (graphical interface, network, etc) were disabled to minimize the overhead.

It should be noted that, while smaller tests were very fast to execute, bigger ones (especially the last two, that only fit on RAM), because of the fact that each test case required a total of 30 executions of the program, were too slow to consider increasing the test size, which could possibly provide a better understanding of the impact the different memory levels have on performance. For example, the RAM\_1 test only uses 5MB of memory, while the cache L2 of the laptop can hold 3MB. This small difference could mean that some of the data might get cached in the L2, thus not providing the expected results, since this test aimed to measure main memory traffic.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SECTION 4: TEST RESULTS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Test Results}
\label{ref:4}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSECTION 4.1. MEMORY ACCESSES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Memory Accesses}

After running all test cases, one of the first measurements made was to attempt an estimation of the number of memory accesses (either cache or main memory), and then compare it against the corresponding PAPI counters (PAPI\_LD\_INS and PAPI\_SR\_INS). By analysis of the C code itself this would not be possible, since the use of registers allows many of the implicit memory accesses to be optimized by the compiler. So it was necessary to analyze the Assembly code generated from the compiler.

After analyzing the structure of the Assembly code, the main loops were identified. They followed the same flow from the C algorithm, which is shown in \autoref{lst:assembly}, along with the number of load/store instructions in each region

\begin{lstlisting}[label=lst:assembly]
	for(1 to N) {
		[4 stores, 1 load, 7 instr.]
		for(1 to N) {
			[6 stores, 3 loads, 34 instr.]
		}
		[3 stores, 6 loads, 26 instr.]
	}
	for(1 to N) {
		[3 stores, 3 loads, 10 instr.]
	}
\end{lstlisting}

Based on this code structure, the formulas to estimate the number of memory accesses and total number of instructions can be easily deduced:

\begin{IEEEeqnarray}{CrClC}
\Rightarrow		&	\mathrm{\#MemAccesses}	&	=	&	(9N + 14)N + 6N	&	\Leftrightarrow	\nonumber	\\
				&							&	=	&	9N^{2} + 20N	&	\nonumber
\end{IEEEeqnarray}

\begin{IEEEeqnarray}{CrClC}
\Rightarrow		&	\mathrm{\#TotalIns}		&	=	&	(34N + 33)N + 10N	&	\Leftrightarrow	\nonumber	\\
				&							&	=	&	34N^{2} + 43N		&	\nonumber
\end{IEEEeqnarray}

\autoref{fig:memaccesses} and \autoref{fig:memaccesseserror} show the estimation calculated from these formulas, along with the approximated value returned from PAPI, and the error of the estimation. The estimation based on assembly analysis proved to be quite accurate. The estimation is very precise, with the error being near 0\% for the bigger cases.

\begin{figure}[!htp]
	\includegraphics[width=\columnwidth]{images/chart01_mem_accesses}
	\caption{Memory Accesses (log scale) \label{fig:memaccesses}}
\end{figure}
\begin{figure}[!htp]
	\includegraphics[width=\columnwidth]{images/chart02_mem_accesses_error}
	\caption{Estimation Error (log scale) \label{fig:memaccesseserror}}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSECTION 4.2. Miss rates
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Cache usage}

Usage of both levels of cache was estimated with specific counters. PAPI\_L1\_DCA and PAPI\_L2\_DCA provided the number of data accesses to the caches, while PAPI\_L1\_DCM and PAPI\_L2\_DCM provided number of misses. It should be noted that the counters for L2 cache are not native, and there were some problems using them, like negative values on some first tests. This might indicate that those counters are not fully reliable.

The charts in this section give information about cache misses and memory accesses. \autoref{fig:cachel1} and \autoref{fig:cachel2} show the total number of accesses and misses for each cache level.

\begin{figure}[!htp]
	\includegraphics[width=\columnwidth]{images/chart03_cache_l1}
	\caption{Cache L1 (log scale) \label{fig:cachel1}}
\end{figure}
\begin{figure}[!htp]
	\includegraphics[width=\columnwidth]{images/chart04_cache_l2}
	\caption{Cache L2 (log scale) \label{fig:cachel2}}
\end{figure}

For both cache levels, the number of accesses increase with the test size, as expected. It can be noticed that when the problem size exceeds size of L1 cache, L1 miss rate increases significantly, and the same can be said for L2 cache when problem size exceeds it's capacity. This is expected, since if the problem can completely fit on cache, then most of the misses become compulsory misses. With an increase in size, misses will happen more often since it will be required to access higher memory levels to retrieve data that could not fit in the cache.

\begin{figure}[!htp]
	\begin{center}
		\includegraphics[width=0.5\textwidth]{images/chart05_cache_miss_perc}
		\caption{Cache miss \% \label{fig:cachemiss}}
	\end{center}
\end{figure}

Looking at cache misses percentage on \autoref{fig:cachemiss}, it can also be noticed that for test cases that fit L1 cache, the L1 miss rate is nearly zero, and the same happens for L2 miss rate in cases that fit L2, although with an even lower miss rate.
As for problems that only fit on main memory (RAM\_1 and RAM\_2), L2 misses are much bigger, which is the obvious and expected behavior. L1 miss count also increases, linearly with problem size, but miss percentage remains the same as in the L2 test cases. This is also expected since for both cases, even though a high miss count should happen on L1, that count should remain proportional to the test size on both cases. The problem already doesn't fit on L1 in the L2\_1 and L2\_2 tests, so the percentage of data that L1 would try to fetch should be roughly the same.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSECTION 4.3. BYTES READ FROM RAM
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Bytes Read from RAM}

Since PAPI did not provide any counter to directly get the number of bytes actually fetched from RAM, this had to be done by estimation. It was assumed that, for each L2 cache miss, there would be a corresponding read from RAM. This makes sense, since after a miss, the next memory level should provide the data.

When reading from RAM, usually a whole cache line is fetched, which in the laptop used, is 64 Bytes long. So the the formula to estimate total bytes read is

$$Bytes\_Read = PAPI\_L2\_DCM * 64$$

\autoref{tab:bytesfromram} shows the resulting estimation from this formula for each test case

\begin{table}[!htp]
	\begin{center}
		\begin{tabular}{|c|c|c|}
			\hline
			\textbf{Test}	&	\textbf{Test Size}	&	\textbf{Amount read}	\\
			\hline
			L1\_1			&	5 KB				&	512 B					\\	
			L1\_2			&	10 KB				&	640 B					\\
			L2\_1			&	0.625 MB			&	115 KB					\\
			L2\_2			&	1.25 MB				&	618 KB					\\
			RAM\_1			&	5 MB				&	304 GB					\\
			RAM\_2			&	10 MB				&	1.25 TB					\\
			\hline
		\end{tabular}
	\end{center}
	\caption{Bytes read from RAM \label{tab:bytesfromram}}
\end{table}

This was the first attempt, although naive, to estimate this value, and it is clear that it is not correct. For example, for the first four test cases, estimated bytes read are actually lower than total problem size, which should not happen, since at least for compulsory misses, it was expected that all data was read at least once.

Also, for the last two test cases, a different estimation can be attempted to compare the result. Assuming the in-existence of both L1 and L2 cache (all memory accesses go directly to RAM), and assuming test case RAM\_2 with 10 MB, which has a total size N=131072, and a complexity of $\Theta (N^{2})$ (each object interacts once with every other body), total bytes read can be estimated with:

$$Bytes\_Read = 131072^{2} * 640$$

\begin{IEEEeqnarray}{CrClC}
\Rightarrow	Bytes\_Read	&	=	&	N^{2} * Object\_Size	&	\Leftrightarrow	\nonumber	\\
						&	=	&	131072^{2} * 80 Bytes	&	\Leftrightarrow	\nonumber	\\
						&	=	&	1.25 TB					&	\nonumber					\\
\end{IEEEeqnarray}

This shows that, when not considering cache (and also not registers, but their quantity should be suppressed by the size of the problem, and the lack of spacial locality between iterations, giving still a somewhat accurate result), a total of 1.25 TB would be read from RAM. Since PAPI results give an L2 miss rate around 50\%, the expected amount of bytes read should be 50\% of 1.25 TB, which is not the case. This can be explained by one of two possibilities.

Either PAPI results are not reliable, which is possible since L2 counters are derived, and it's calculation is architecture-dependent and is not explained in the documentation, so some approximations and probabilistic results may be used. Or there is some functionality implemented by the hardware cache hierarchy that is unknown and should have been considered in this estimation.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% SUBSECTION 4.4. OPERATIONAL INTENSITY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Operational Intensity}

With the already shown results, operational intensity could be estimated based on bytes read from memory and total amount of floating point operations. It only makes sense to calculate this value for test sizes that will only fit on RAM, so only RAM\_1 and RAM\_2 tests were considered. Bytes read from ram were estimated with results from the previous section, which was based on number of L2 misses, and cache line size. floating point operations were given by PAPI\_FP\_OPS counter. So the general formula to estimate operational intensity is:

$$Op\_Intensity = \frac{PAPI\_FP\_OPS}{PAPI\_L2\_DCM * 64}$$

For both RAM test cases, operational intensity of nearly 0.2, which puts the algorithm in a position of the roofline model where it is clearly memory-bounded by the architecture.

Other N-Body algorithms have already been developed, and are not studied here, but it is likely that they have better results, as this is the most naive approach to this problem.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%% BIBLIOGRAPHY
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{thebibliography}{9}
\bibitem{roofline}
	\texttt{\small
	Roofline: An insightful Visual Performance Model for Floating-Point Programs and Multi-core Architectures}	\\
	\emph{Samuel Webb Williams, Andre Waterman, David A. Patterson}	\\
	28th November 2011

\bibitem{ark}
	\small{http://ark.intel.com/products/35568/Intel-Core2-Duo-Processor-P8600}	\\
	\emph{Intel{\textregistered} Core 2 Duo{\texttrademark} P8600}	\\
	{\copyright}Intel Corporation	\\
	28th November 2011

\bibitem{intelmanual}
	\small{Intel{\textregistered} 64 and IA-32 Architectures Software Developer Manuals}	\\
	{\copyright}Intel Corporation	\\
	29th November 2011

\bibitem{sqrt}
	Best Square Root Method - Algorithm - Function (Precision VS Speed)	\\
	http://www.codeproject.com/KB/cpp/Sqrt\_Prec\_VS\_Speed.aspx	\\
	\emph{Mahmoud Hesham El-Magdoub} \\
	15th September 2010

\end{thebibliography}

\end{document}
